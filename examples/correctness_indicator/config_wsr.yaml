# Configuration for correctness indicator example
max_iterations: 10
checkpoint_interval: 5

# LLM configuration
llm:
  models:
    - name: "deepseek-chat"
      weight: 1.0
  api_base: "https://api.deepseek.com"
  api_key: ${OPENAI_API_KEY}
  temperature: 0.7
  max_tokens: 8192
  timeout: 120

# Prompt configuration
prompt:
  system_message: |
    You are an expert programmer specializing in correctness indicators for LLM-generated solutions. Your task is to evolve and improve a confidence score calculation algorithm that analyzes logprobs from LLM traces to determine answer confidence.
    
    OPTIMIZATION GOAL:
    Your objective is to maximize the separation between correct and incorrect answers. 
    
    IMPORTANT: You don't need to worry about the final score range or the squashing/normalization logic; focus only on creating a Raw Score in the `calculate_confidence` function where correct traces have a distinct distribution from incorrect ones. An external optimizer in `compute_confidence_score` will automatically perform a grid search to find the best Tanh normalization parameters to map your raw scores to the [-1, 1] range.
    
    This will enable weighted majority voting to produce more accurate final answers by giving more weight to high-confidence (and thus more likely correct) traces.
    
    CONSTRAINTS:
    - Each trace contains logprobs for the entire solution
    - Your compute_confidence_score() function must return List[Tuple[float, bool]] where each tuple is (confidence_score, is_correct)
    - The function should accept an optional input_file parameter (supports wildcard patterns like 'aime_traces/1_*_labeled.jsonl')

# Database configuration
database:
  population_size: 50
  archive_size: 20
  num_islands: 3
  elite_selection_ratio: 0.2
  exploitation_ratio: 0.7

  # embedding_model: "text-embedding-3-small"
  similarity_threshold: 0.99

# Evaluator configuration
evaluator:
  timeout: 180
  cascade_evaluation: false
  cascade_thresholds: [1.3]
  parallel_evaluations: 3
  validation_file: "./data/20260111_043209_traces_Qwen3-8B-AWQ_kv_auto_t0.6_p0.95_max32000_n64_swap4/val_split.jsonl"
  enable_validation: false

# Evolution settings
diff_based_evolution: true
max_code_length: 20000
